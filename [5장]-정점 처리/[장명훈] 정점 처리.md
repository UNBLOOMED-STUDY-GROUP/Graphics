# Rendering Pipline

![image](https://github.com/user-attachments/assets/a05b5bec-0e32-48a9-b800-679514ffa989)
- 정점 처리 *(vertex processing)*
    - 정점 버퍼의 정점에 대해 변환 등의 연산 수행
    - 정점 **위치** 정보 결정
    
- 래스터화 *(rasterization)*
    - 변환된 정점으로 정의된 폴리곤 내부를 채우는 프래그먼트 생성
    - 프로그램 불가 영역(불칸 제외)

- 프래그먼트 처리 (*fragment processing*)
    - 각각의 프래그먼트에 대해서 텍스쳐링 등의 작업을 거쳐 **색상**을 결정
    - 프래그먼트: 컬러 버퍼의 픽셀을 수정하는 데 필요한 데이터 모음
    - 컬러 버퍼: 화면을 구성하는 픽셀 전체가 저장되는 메모리 공간

- 출력 병합 (*output merging*) : 프래그먼트와 현재 컬러버퍼 픽셀을 결합하거나 선택하여 컬러 버퍼 수정

이 파트는 정점 처리를 중심으로 정리

# 정점 처리 (vertex processing)

> 정점 버퍼의 정점에 대해 변환 등의 연산 수행 = 위치 결정
> 
![image](https://github.com/user-attachments/assets/c57564cb-3f33-48e2-a7f5-b62ffb57c8fb)


## World Transform 변환
> - Object space → World Space 변환
> - 객체를 로컬 좌표계(object space)에서 월드 좌표계(world space)로 변환하는 과정
> - vertex position에는 4장에서 배운 Scaling, Rotation, Translation이 여기서 일어난다.
> - vertex normal에는 L의 역행렬 + 전치 행렬을 곱한다. 

### vertex normal
> 특정 버텍스(정점)의 방향을 나타내는 단위 벡터
> 
Non-Uniform Scaling일 경우, vertex normal은 L이 아닌 L의 역행렬 + 전치 행렬을 곱해야 정상 적용이 된다. 그래야 법선벡터도 수직으로 유지된다.

$$
(L^(-1))^T
$$

![image](https://github.com/user-attachments/assets/fc5759de-18f4-4845-b5ef-d09f76a75774)

## View Transform

> - 월드 공간 좌표 → 카메라 공간 좌표로 변환
> - 카메라(또는 관찰자)의 위치와 방향을 기준으로 장면을 재배치하는 역할

- 월드 변환하면 모든 물체는 월드 공간에 모임
- 카메라 파라미터 설정
    - **EYE**: 카메라 위치
    - **AT**: 카메라가 바라보는 기준점
    - **UP**: 카메라 상단을 가리키는 방향을 대략적으로 묘사한 벡터 (대게, **UP** 은 월드 공간의 *y* 축으로 설정)
- 카메라 공간(*camera space*) : 카메라 원점과 기저(basis)로 생성{**EYE**, *u*, *v*, *n*}
![image](https://github.com/user-attachments/assets/de2a0d4b-e86c-4a9a-9c3a-91b6e6bd1896)


### Space change

- 이동에 의해서 월드 공간과 카메라 공간은 원점을 공유함.
- 회전 : *u*, *v*, *n* 이 *e*1, *e*2, *e*3 ,에 포개지도록 *Ru=e*1, *Rv=e*2, *Rn=e*3.
- 회전변환 *R* : 기저 이전 (*basis change*), {*e*1, *e*2, *e*3} -> {*u*, *v*, *n*}.
- 카메라 공간 기저 벡터를 차례로 행에 배치
- 뷰 행렬 view matrix

![image](https://github.com/user-attachments/assets/bc4ef2c6-9a09-425e-8d04-d04edc019869)


### View Frustum

- 카메라 공간 기저를 {*u*, *v*, *n*} 대신에 {*x*, *y*, *z*} 라고 하자
- 카메라 외부 파라미터 : **EYE**, **AT**, **UP**
- 카메라 내부 파라미터
    - 카메라 렌즈를 선택하고 줌인/줌아웃을 제어하는 것과 유사
    - 뷰 프러스텀 (절두체, *view frustum*) 파라미터 : *fovy*, *aspect*, *n*, *f*
    - *fovy* (field of view Y) : 수직시야각
    - *aspect* : 종횡비
    - *n* : 전방평면거리
    - *f* : 후방평면거리
- 전방/후방 평면은 실시계와 다르지만 계산상 효율성을 위해서 사용됨
![image](https://github.com/user-attachments/assets/5ec3cae7-6ebb-4f02-bf35-acf5cf7f0784)

### 뷰 프러스텀 컬링 (View-frustum culling)

- 폴리곤 메쉬를 감싸는 직육면체 혹은 구 (바운딩 볼륨)을 미리 계산하고, CPU 프로그램에서 바운딩 볼륨이 뷰 프러스텀 바깥에 있는 지 테스트해서, 그렇다면 폴리곤 메쉬는 렌더링 파이프라인에서 제외
- 약간의 CPU 비용으로 상당한 GPU 계산 비용 절감을 얻음
- 그림 : 원통과 구는 뷰 프러스텀 컬링에서 제거됨
![image](https://github.com/user-attachments/assets/1e825362-0e65-47bb-ad3f-bcc0143b1197)

- 주전자 손잡이 폴리곤이 뷰 프러스텀과 교차할 경우, 이 폴리곤은 잘라져서 프러스텀 안쪽 부분만 GPU 파이프라인으로 넘어감
- 하지만 뷰 프러스텀에서 폴리곤을 자르는 (클리핑) 하는 것은 쉽지 않음

## Projection Transform

> - 카메라 좌표계에서 클립 좌표계(clip space)로 변환하는 과정입니다. 
> - 3D 장면을 2D 화면에 투영하는 역할
> - 크게 두 가지로 나뉜다.

- 뷰 프러스텀을 클립 공간(clip space, 축에 정렬된 2x2x1 직육면체)로 변환하고 폴리곤도 변환하면, 클립 공간의 변환된 폴리곤의 클리핑은 쉬움
![image](https://github.com/user-attachments/assets/06ef2d80-3829-47e9-9c23-937867c6df28)

- 카메라 위치 원점 = 투영 중심( center of projection: COP)
- 투영선에 위치한 모든 3D 점은 투영 평면의 한 점에 맺힘. 멀리 있는 물체는 작게 보이는 원근 투영(perspective projection)을 함.
- 원근 투영: 투영 변환 후 뷰 프러스텀은 직육면체로 바뀌고 COP는 무한히 멀어지고 투영선은 평행해지고 단일한 투영방향을 가짐
- 직교 투영(*orthographic projection*.) : 단일한 투영방향을 가지는 투영

![image](https://github.com/user-attachments/assets/37c3cd65-5290-4c5c-9786-f36d55af841b)

- 투영 변환 행렬

![image](https://github.com/user-attachments/assets/c414fd0b-9657-48e9-bd72-a29586a7e7c5)

- 투영 변환된 물체는 래스터화 단계로 보내짐
- 정점 처리 단계와 달리, 래스터화 단계는 하드웨어에서 처리하고, 클립 공간은 왼손좌표계로 처리됨.
    - 왼손좌표계로 전환이 필요: 물체의 z축 부호를 바꿈
    - 왼손클립공간 투영행렬 : 세 번째 행 부호 바꿈
- 투영 변환 후 카메라공간 (RHS) 에서 클립 공간 (LHS) 으로 바뀜

