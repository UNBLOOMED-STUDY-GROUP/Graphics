



- GPU렌더링 파이프라인 아키텍처
    - 버텍스 쉐이더
        - 폴리곤 메쉬가 드로우콜에 의해 GPU에 입력이 된다.
        - 폴리곤 버텍스들을 버텍스 Array에 저장된다.
        - 버텍스 쉐이더는 버텍스 Array의 내용을 하나씩 불러들이며 연산을 수행한다
    - rasterizer
        - 인덱스 어레이의 정보를 이용하여 삼각형을 다시 조립
        - 픽셀의 색상 정보를 rasterizer가 모은다
        - 
    - 프레그먼트 쉐이더
        - 실제 색상을 결정한다
    - Output merger
        - 결정된 색상을 보여줄지, 만약 보여준다면 어떤 형태로 보여줄 지 결정하여 출력



- 오브젝트 스페이스부터 클립 스페이스까지
    - 오브젝트 공간 - 월드 공간 - 카메라 공간 - 클립 스페이스로 진행
    - 버택스 쉐이더



- 월드 변환
    - 만약 x,y축에 평행한 벡터와 그 벡터의 노말이 있을 때 이 노말에 non-uniform scaling 월드 변환이 들어오면 노말벡터가 변하는 상황이 생긴다.
    - 결국 L이 non-uniform scaling을 가지고 있을 때는 L의 inverse transpose를 적용해야 한다.(L의 역행렬의 T를 취한다)


- 뷰 트랜스폼
    - EYE : 카메라의 위치
    - AT : 카메라의 에임이 위치할 정면 포인트
    - UP : 카메라의 UPVector
    - EYE와 UP으로 u,v,n정의 가능
        - n =  eye-at / ||eye-at||
        - u = UP * N / || UP * n ||
        - v = n * u
            - v를 자기 자신으로 나누지 않는 이유는(normalize하지 않는 이유는) n과 u가 이미 normalize상태이기 때문
        - 이렇게 정의된 n,u,v는 모두 단위벡터이며 수직이다



- 뷰트랜스폼과 월드트랜스폼을 일치시키기
    - 뷰 트랜스폼을 월드 트랜스폼의 위치로 옮기기
        - EYE의 Translation진행
        - 카메라가 이동하면 뷰 트랜스폼의 오브젝트도 같이 이동
    - Translation을 적용한 뒤 Rotation을 적용하면 오브젝트의 좌표를 통해 카메라의 좌표를 얻을 수 있음
    - 아래의 영상의 gif를 확인하자


- 왼손 vs 오른손 좌표계
    - 오른손 좌표계랑 왼손 좌표계에 각각 오브젝트를 그리고 화면에 투영시키면 반대로 나온다.
    - 만약 왼손좌표계에서 오른존 좌표계처럼 표현하고 싶다면 Z값에 -1곱하면 된다.


- view frustum
    - 시야각(FOVy) 및 종횡비(aspect)조절
    - n(near)과 f(far)를 통해 너무 가까운, 너무 먼 위치를 안보이게 선언한다.
    - 그리고 그 범위에서 벗어나는 오브젝트들은 view frustum culling(뷰 플러스터 컬링)을 통해 제거한다.
    - 만약 위의 자료처럼 일부만 범위 안쪽에 있다면 남은 부분을 클리핑 처리한다.
    - 하지만 피라미드에서 오브젝트를 클리핑한다는 것은 쉽지 않다.


- projection transform
    - 뷰 플러스텀을 정육면체로 정의한 것.
    - 이 projection transfrom을 오브젝트에 정의하고 클리핑 진행.
    - proojection transform으로 변환되면 뷰 스페이스에서 클립 스페이스로 변환된다.
    
    - 카메라에서 필름역할을 하는 것을 projection plane이라고 칭한다
    - projection line을 통해 같은 비율로 평면에 투영한다.
    - 해당 영상을 참고하자


행렬 계산

- Projection Transform Matrix
    - vertex shader작업이 완료된 좌표계를 레스터라이저로 전달될 때 왼손 좌표계로 변환되어 전송되어야 한다.
